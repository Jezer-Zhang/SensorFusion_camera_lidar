{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3680af60-1efd-4b28-a752-bf1fa33aece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0411fc32-2510-4c0a-a8c0-e2c13ae236e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/256\n",
      "270/256\n",
      "280/256\n"
     ]
    }
   ],
   "source": [
    "# lidar 2 tensor\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Class for the calibration matrices for KITTI data\n",
    "class Calibration:\n",
    "    def __init__(self, calib_filepath):\n",
    "        calibs = self.read_calib_file(calib_filepath)\n",
    "\n",
    "        self.P = calibs['P2']\n",
    "        self.P = np.reshape(self.P, [3,4])\n",
    "\n",
    "        self.L2C = calibs['Tr_velo_to_cam']\n",
    "        self.L2C = np.reshape(self.L2C, [3,4])\n",
    "\n",
    "        self.R0 = calibs['R0_rect']\n",
    "        self.R0 = np.reshape(self.R0,[3,3])\n",
    "\n",
    "    @staticmethod\n",
    "    def read_calib_file(filepath):\n",
    "        data = {}\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.rstrip()\n",
    "                if len(line)==0: continue\n",
    "                key, value = line.split(':', 1)\n",
    "                try:\n",
    "                    data[key] = np.array([float(x) for x in value.split()])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        return data\n",
    "    \n",
    "    # From LiDAR coordinate system to Camera Coordinate system\n",
    "    def lidar2cam(self, pts_3d_lidar):\n",
    "        n = pts_3d_lidar.shape[0]\n",
    "        pts_3d_hom = np.hstack((pts_3d_lidar, np.ones((n,1))))\n",
    "        pts_3d_cam_ref = np.dot(pts_3d_hom, np.transpose(self.L2C))\n",
    "        pts_3d_cam_rec = np.transpose(np.dot(self.R0, np.transpose(pts_3d_cam_ref)))\n",
    "        return pts_3d_cam_rec\n",
    "    \n",
    "    # From Camera Coordinate system to Image frame\n",
    "    def rect2Img(self, rect_pts, img_width, img_height):\n",
    "        n = rect_pts.shape[0]\n",
    "        points_hom = np.hstack((rect_pts, np.ones((n,1))))\n",
    "        points_2d = np.dot(points_hom, np.transpose(self.P)) # nx3\n",
    "        points_2d[:,0] /= points_2d[:,2]\n",
    "        points_2d[:,1] /= points_2d[:,2]\n",
    "        \n",
    "        mask = (points_2d[:,0] >= 0) & (points_2d[:,0] <= img_width) & (points_2d[:,1] >= 0) & (points_2d[:,1] <= img_height)\n",
    "        mask = mask & (rect_pts[:,2] > 2)\n",
    "        return points_2d[mask,0:2], mask\n",
    "\n",
    "# From Github https://github.com/balcilar/DenseDepthMap\n",
    "def dense_map(Pts, n, m, grid): # something wrong!  \n",
    "    # Actually there are a lot of errors in python script, because he forgets that the array begins in matlab with 1 but in python 0, which means array[0](in python)=array[1](in matlab). And if a range is (a:b), in matlab 'b' will be included and in python 'b' is excluded. \n",
    "    ng = 2 * grid + 1\n",
    "    \n",
    "    mX = np.zeros((m,n)) + float(\"inf\")\n",
    "    mY = np.zeros((m,n)) + float(\"inf\")\n",
    "    mD = np.zeros((m,n))\n",
    "    mX[np.int32(Pts[1]),np.int32(Pts[0])] = Pts[0] - np.round(Pts[0])\n",
    "    mY[np.int32(Pts[1]),np.int32(Pts[0])] = Pts[1] - np.round(Pts[1])\n",
    "    mD[np.int32(Pts[1]),np.int32(Pts[0])] = Pts[2]\n",
    "    \n",
    "    KmX = np.zeros((ng, ng, m - ng, n - ng))\n",
    "    KmY = np.zeros((ng, ng, m - ng, n - ng))\n",
    "    KmD = np.zeros((ng, ng, m - ng, n - ng))\n",
    "    \n",
    "    for i in range(ng):\n",
    "        for j in range(ng):\n",
    "            KmX[i,j] = mX[i : (m - ng + i), j : (n - ng + j)] - grid - 1 +i\n",
    "            KmY[i,j] = mY[i : (m - ng + i), j : (n - ng + j)] - grid - 1 +i\n",
    "            KmD[i,j] = mD[i : (m - ng + i), j : (n - ng + j)]\n",
    "    S = np.zeros_like(KmD[0,0])\n",
    "    Y = np.zeros_like(KmD[0,0])\n",
    "    \n",
    "    for i in range(ng):\n",
    "        for j in range(ng):\n",
    "            s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
    "            Y = Y + s * KmD[i,j]\n",
    "            S = S + s\n",
    "    \n",
    "    S[S == 0] = 1\n",
    "    out = np.zeros((m,n))\n",
    "    out[grid + 1 : -grid, grid + 1 : -grid] = Y/S\n",
    "    return out\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# From Github https://github.com/BerensRWU/DenseMap#readme\n",
    "# From Github https://github.com/balcilar/DenseDepthMap\n",
    "\n",
    "def dense_map_new(lidarOnImage, n, m, grid):\n",
    "    # remove out of image size indexes\n",
    "    mask = (lidarOnImage[:, :2] >= 1).all(axis=1)\n",
    "    Pts = lidarOnImage[mask].T\n",
    "\n",
    "    ng = 2 * grid + 1\n",
    "\n",
    "    mX = np.zeros((m,n)) + float(\"inf\") # inf-matrix\n",
    "    mY = np.zeros((m,n)) + float(\"inf\") # inf-matrix\n",
    "    mD = np.zeros((m,n))\n",
    "    mX[np.int32(np.round(Pts[1])-1),np.int32(np.round(Pts[0])-1)] = Pts[0] - np.round(Pts[0])\n",
    "    mY[np.int32(np.round(Pts[1])-1),np.int32(np.round(Pts[0])-1)] = Pts[1] - np.round(Pts[1])\n",
    "    mD[np.int32(np.round(Pts[1])-1),np.int32(np.round(Pts[0])-1)] = Pts[2]\n",
    "\n",
    "    KmX = np.zeros((ng, ng, m - 2*grid, n - 2*grid))\n",
    "    KmY = np.zeros((ng, ng, m - 2*grid, n - 2*grid))\n",
    "    KmD = np.zeros((ng, ng, m - 2*grid, n - 2*grid))\n",
    "\n",
    "    for i in range(ng):\n",
    "        for j in range(ng):\n",
    "            KmX[i,j] = mX[i : (m - 2*grid + i), j : (n - 2*grid + j)] - grid + j\n",
    "            KmY[i,j] = mY[i : (m - 2*grid + i), j : (n - 2*grid + j)] - grid + i\n",
    "            KmD[i,j] = mD[i : (m - 2*grid + i), j : (n - 2*grid + j)]\n",
    "\n",
    "    S = np.zeros_like(KmD[0,0])\n",
    "    Y = np.zeros_like(KmD[0,0])\n",
    "\n",
    "    for i in range(ng):\n",
    "        for j in range(ng):\n",
    "            s = 1/np.sqrt(KmX[i,j] * KmX[i,j] + KmY[i,j] * KmY[i,j])\n",
    "            Y = Y + s * KmD[i,j]\n",
    "            S = S + s\n",
    "\n",
    "    S[S == 0] = 1\n",
    "    out = np.zeros((m,n))\n",
    "    out[grid : -grid, grid  : -grid] = Y/S\n",
    "    return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = \"../../public/dataset_expensive_storage/KITTI/testing/\"\n",
    "    image_dir = os.path.join(root, \"image_2\")\n",
    "    velodyne_dir = os.path.join(root, \"velodyne\")\n",
    "    calib_dir = os.path.join(root, \"calib\")\n",
    "\n",
    "    tensors_max = torch.tensor(80, dtype=torch.float32)\n",
    "    tensors_min = torch.tensor(0, dtype=torch.float32)\n",
    "    \n",
    "    depths_max_list = []\n",
    "    length = 256\n",
    "    \n",
    "    # Data id\n",
    "    for i in range(256,288):\n",
    "        cur_id = i\n",
    "        if i%10 ==0:\n",
    "            print(f'{i}/{length}')\n",
    "        # Loading the image\n",
    "        img = cv2.imread(os.path.join(image_dir, \"%06d.png\" % cur_id))\n",
    "        # Loading the LiDAR data\n",
    "        lidar = np.fromfile(os.path.join(velodyne_dir, \"%06d.bin\" % cur_id), dtype=np.float32).reshape(-1, 4)\n",
    "        # Loading Calibration\n",
    "        calib = Calibration(os.path.join(calib_dir, \"%06d.txt\" % cur_id))\n",
    "        # From LiDAR coordinate system to Camera Coordinate system\n",
    "        lidar_rect = calib.lidar2cam(lidar[:,0:3])\n",
    "        # From Camera Coordinate system to Image frame\n",
    "        lidarOnImage, mask = calib.rect2Img(lidar_rect, img.shape[1], img.shape[0])\n",
    "        # Concatenate LiDAR position with the intesity (3), with (2) we would have the depth\n",
    "        lidarOnImage = np.concatenate((lidarOnImage, lidar_rect[mask,2].reshape(-1,1)), 1)\n",
    "\n",
    "        # print(lidarOnImage.shape) --> (20285, 3)\n",
    "\n",
    "        # 1. create depth map\n",
    "        points = lidarOnImage.T\n",
    "        # print(points.shape)\n",
    "        u, v, depths = points\n",
    "\n",
    "        convert_tensor = transforms.ToTensor()\n",
    "        points = convert_tensor(points)\n",
    "        # print(points.shape)\n",
    "\n",
    "        depths = torch.tensor(depths)\n",
    "\n",
    "\n",
    "        IMG_W = img.shape[1]\n",
    "        IMG_H = img.shape[0]\n",
    "        # print(IMG_H,IMG_W) --> 370 1224\n",
    "\n",
    "        tensor_save = torch.zeros((1,IMG_H,IMG_W))\n",
    "\n",
    "        dim0, dim1, dim2 = points.shape\n",
    "        for i in range(dim2):\n",
    "            y = points[0,0,i]\n",
    "            y = y.long()\n",
    "            x = points[0,1,i]\n",
    "            x = x.long()\n",
    "            z = depths[i]\n",
    "            z = z.long()\n",
    "            tensor_save[0,x,y] = z\n",
    "        # print(tensor_save.shape)\n",
    "        name = \"%06d.pth\" % cur_id\n",
    "        tensor_save = tensor_save[0,150:350, 600:800].unsqueeze(0)\n",
    "        # depth_max = torch.max(tensor_save)\n",
    "        # depths_max_list.append(depth_max)\n",
    "\n",
    "        tensor_save = (tensor_save-tensors_min)/(tensors_max-tensors_min)\n",
    "        tensor_save = tensor_save.float()\n",
    "        torch.save(tensor_save, f'testdataset/lidar_tensor/sparse/{name}')\n",
    "\n",
    "\n",
    "\n",
    "    # print(max(depths_max_list))\n",
    "\n",
    "#     print(tensor_save.shape)        \n",
    "\n",
    "\n",
    "\n",
    "#         # 2. interpolation --> create dense depth map\n",
    "#         out = dense_map_new(lidarOnImage, img.shape[1], img.shape[0], 6)\n",
    "#         out_tensor = torch.unsqueeze(torch.from_numpy(out), dim=0)\n",
    "#         # print(out_tensor.max())\n",
    "#         out_tensor = out_tensor[0,150:350, 600:800].unsqueeze(0)\n",
    "\n",
    "#         name = \"%06d.pth\" % cur_id\n",
    "\n",
    "#         # resized_tensor = F.interpolate(out_tensor.unsqueeze(0), size=(100, 400), mode='bilinear', align_corners=False)\n",
    "#         # resized_tensor = torch.squeeze(resized_tensor).unsqueeze(0)\n",
    "#         # print(resized_tensor.max())\n",
    "\n",
    "#         out_tensor = (out_tensor-tensors_min)/(tensors_max-tensors_min)\n",
    "#         out_tensor = out_tensor.float()\n",
    "#         # print(resized_tensor.shape)\n",
    "#         torch.save(out_tensor, f'testdataset/lidar_tensor/dense/{name}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d6f5ca-1e61-4e9f-9175-6a4edc6a74eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "successful!\n"
     ]
    }
   ],
   "source": [
    "# # A. mask / cut out\n",
    "\n",
    "# import torch\n",
    "# import glob\n",
    "# import cv2\n",
    "# import os\n",
    "# import imgaug.augmenters as iaa\n",
    "\n",
    "# # sample_token as name\n",
    "# image_list = []\n",
    "# ori_img_name_list = []\n",
    "# damage_label = 'A'\n",
    "\n",
    "# image_path = 'image_gray_200_original'\n",
    "# images = sorted(glob.glob(image_path + '/*'))\n",
    "\n",
    "\n",
    "# for i in range(len(images)):\n",
    "\n",
    "#         image = cv2.imread(images[i])\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#         image_list.append(image)\n",
    "#         ori_img_name = os.path.basename(images[i])\n",
    "#         ori_img_name_list.append(ori_img_name)\n",
    "\n",
    "\n",
    "# # print(len(image_list))\n",
    "    \n",
    "# seq = iaa.Sequential([\n",
    "#     iaa.Cutout(nb_iterations=(4, 6), size=0.2, squared=False, random_state = 1 )\n",
    "#     , ])\n",
    "\n",
    "# images_aug_list = seq.augment_images(image_list)\n",
    "# print(len(images_aug_list))\n",
    "\n",
    "# for index in range(len(images_aug_list)):\n",
    "#     # s = '%05d' % (index+1) # name format 00001\n",
    "#     s = ori_img_name_list[index]\n",
    "#     cv2.imwrite(f'testdataset/damaged_image/{damage_label}_{s}', images_aug_list[index])\n",
    "\n",
    "# print('successful!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe2716b-6a14-4e0d-9be2-7e749dd7b98c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A. for later regionla mse\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def create_mask(image_shape, block_size, num_blocks):\n",
    "    mask = np.ones(image_shape, dtype=np.float32) \n",
    "    block_size_px = (int(image_shape[0] * block_size), int(image_shape[1] * block_size))\n",
    "    np.random.seed(6)\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        top_left = np.random.randint(0, image_shape[0] - block_size_px[0] + 1), np.random.randint(0, image_shape[1] - block_size_px[1] + 1)\n",
    "        bottom_right = top_left[0] + block_size_px[0], top_left[1] + block_size_px[1]\n",
    "        mask[top_left[0]:bottom_right[0], top_left[1]:bottom_right[1]] = 0\n",
    "        \n",
    "    return mask\n",
    "\n",
    "\n",
    "image_list = []\n",
    "ori_img_name_list = []\n",
    "image_path = 'testdataset/ori_image'\n",
    "images = sorted(glob.glob(image_path + '/*'))[0:32]\n",
    "damage_label = 'A'\n",
    "\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ori_img_name = os.path.basename(images[i])\n",
    "\n",
    "    block_size = 0.2  # 方块大小为原图大小的百分比\n",
    "    num_blocks = 16  # 方块数量\n",
    "    mask = create_mask(image.shape[:2], block_size, num_blocks)\n",
    "    damaged_img1 = image * mask\n",
    "    cv2.imwrite(f'testdataset/damaged_image/{damage_label}_{ori_img_name}', damaged_img1)\n",
    "\n",
    "    # cv2.imwrite(f'deepEmsemblesDataset/damaged_image_10/{ori_img_name}', damaged_img1)\n",
    "    # print(image.shape[:2])\n",
    "\n",
    "# # 显示损坏的图像，保留 mask 的效果\n",
    "# plt.imshow(damaged_img1, cmap='gray')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e41894-95e7-46a3-b52f-6942a0f076a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful!\n"
     ]
    }
   ],
   "source": [
    "# B. motionblur\n",
    "\n",
    "# loading library\n",
    "import random\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def motion_blur(img):\n",
    "    # Specify the kernel size.\n",
    "    # The greater the size, the more the motion.\n",
    "    kernel_size = random.randint(40, 70)\n",
    "\n",
    "    # # Create the vertical kernel.\n",
    "    kernel_v = np.zeros((kernel_size, kernel_size))\n",
    "\n",
    "    # Create a copy of the same for creating the horizontal kernel.\n",
    "    kernel_h = np.copy(kernel_v)\n",
    "\n",
    "    # Fill the middle row with ones.\n",
    "    # kernel_v[:, int((kernel_size - 1) / 2)] = np.ones(kernel_size)\n",
    "    kernel_h[int((kernel_size - 1) / 2), :] = np.ones(kernel_size)\n",
    "\n",
    "    # Normalize.\n",
    "    # kernel_v /= kernel_size\n",
    "    kernel_h /= kernel_size\n",
    "\n",
    "    # # Apply the vertical kernel.\n",
    "    # vertical_mb = cv2.filter2D(img, -1, kernel_v)\n",
    "\n",
    "    # Apply the horizontal kernel.\n",
    "    horizonal_mb = cv2.filter2D(img, -1, kernel_h)\n",
    "\n",
    "    return horizonal_mb\n",
    "\n",
    "    # Save the outputs.\n",
    "    # cv2.imwrite('car_vertical.jpg', vertical_mb)\n",
    "    \n",
    "damage_label = 'B'\n",
    "images_aug_list = []\n",
    "ori_img_name_list = []\n",
    "\n",
    "image_path = 'testdataset/ori_image'\n",
    "images = sorted(glob.glob(image_path + '/*'))[32:64]\n",
    "\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i])\n",
    "    image = motion_blur(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ori_img_name = os.path.basename(images[i])\n",
    "\n",
    "    cv2.imwrite(f'testdataset/damaged_image/{damage_label}_{ori_img_name}', image)\n",
    "\n",
    "print('successful!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc06cc2-485a-42e5-b529-f75d2aa86510",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "successful!\n"
     ]
    }
   ],
   "source": [
    "# C. sunflare\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "damage_label = 'C'\n",
    "\n",
    "image_path = 'testdataset/ori_image'\n",
    "images = sorted(glob.glob(image_path + '/*'))[64:96]\n",
    "\n",
    "print(len(images))\n",
    "# fixed src center\n",
    "# 一个list里面加的都一样！不采纳！\n",
    "# flare_images= am.add_sun_flare(image, flare_center=(x,y), angle=-math.pi/4)\n",
    "# hp.visualize(flare_images, column=3)\n",
    "\n",
    "for index in range(len(images)):\n",
    "    img = cv2.imread(images[index])\n",
    "\n",
    "    transform = A.Compose(\n",
    "         [A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), angle_lower=0.5, p=1, src_radius =200)],\n",
    "    )\n",
    "    random.seed()\n",
    "    transformed = transform(image=img)\n",
    "    img = transformed['image']\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ori_img_name = os.path.basename(images[index])\n",
    "    cv2.imwrite(f'testdataset/damaged_image/{damage_label}_{ori_img_name}', image)\n",
    "\n",
    "\n",
    "print('successful!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00a8289b-ef1c-4a56-b120-11d6cc47e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. foggu\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# sample_token as name\n",
    "image_list = []\n",
    "ori_img_name_list = []\n",
    "\n",
    "damage_label = 'D'\n",
    "\n",
    "\n",
    "image_path = 'testdataset/ori_image'\n",
    "images = sorted(glob.glob(image_path + '/*'))[96:128]\n",
    "\n",
    "\n",
    "# for i in range(len(images)):\n",
    "#     image = cv2.imread(images[i])\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     ori_img_name = os.path.basename(images[i])\n",
    "#     # cv2.imwrite(f'../../Dataset/lidar_img_16200/damaged_image_gray/D_fog/{ori_img_name}', image)\n",
    "    \n",
    "    \n",
    "    \n",
    "# for i in range(len(images)):\n",
    "\n",
    "#         image = cv2.imread(images[i])\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#         image_list.append(image)\n",
    "#         ori_img_name = os.path.basename(images[i])\n",
    "#         ori_img_name_list.append(ori_img_name)\n",
    "\n",
    "\n",
    "# seq = iaa.Sequential([\n",
    "#     iaa.imgcorruptlike.Fog(severity=3),] )\n",
    "\n",
    "# images_aug_list = seq.augment_images(image_list)\n",
    "\n",
    "# for index in range(len(images_aug_list)):\n",
    "#     s = ori_img_name_list[index]\n",
    "#     cv2.imwrite(f'../../Dataset/lidar_img_16200/damaged_image_gray/D_fog/{s}', images_aug_list[index])\n",
    "\n",
    "\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_list.append(image)\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.imgcorruptlike.Fog(severity=5),] )\n",
    "\n",
    "images_aug_list = seq.augment_images(image_list)\n",
    "\n",
    "for index in range(len(images_aug_list)):\n",
    "    ori_img_name = os.path.basename(images[index])\n",
    "    cv2.imwrite( f'testdataset/damaged_image/{damage_label}_{ori_img_name}', images_aug_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea56864b-8954-4b93-bc13-ec4493b62f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# E. overexposure\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "\n",
    "\n",
    "def overexposure(img):\n",
    "    # 将bgr转化为hsv\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    img = img.astype(np.float64)\n",
    "    # 获取v通道（颜色亮度通道），并做渐变性的增强\n",
    "    Exp1 = random.randint(75, 90)\n",
    "    Exp2 = random.randint(55, 65)\n",
    "    Exp3 = random.randint(15, 25)\n",
    "\n",
    "    img[:, :, 2] = np.where(img[:, :, 2] > 40, img[:, :, 2] + Exp1, img[:, :, 2])\n",
    "    img[:, :, 2] = np.where(img[:, :, 2] > 140, img[:, :, 2] + Exp2, img[:, :, 2])\n",
    "    img[:, :, 2] = np.where(img[:, :, 2] > 180, img[:, :, 2] + Exp3, img[:, :, 2])\n",
    "\n",
    "    # 令大于255的像素值等于255（防止溢出）\n",
    "    img = np.where(img > 255, 255, img)\n",
    "    img = img.astype(np.uint8)\n",
    "    res = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "    return res\n",
    "\n",
    "images_aug_list = []\n",
    "ori_img_name_list = []\n",
    "damage_label = 'E'\n",
    "\n",
    "image_path = 'testdataset/ori_image'\n",
    "images = sorted(glob.glob(image_path + '/*'))[128:160]\n",
    "\n",
    "print(len(images))\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i])\n",
    "    image = overexposure(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ori_img_name = os.path.basename(images[i])\n",
    "    # cv2.imwrite(f'../../Dataset/lidar_img_16200/damaged_image_gray/E_overexposure/{ori_img_name}', image)\n",
    "    cv2.imwrite(f'testdataset/damaged_image/{damage_label}_{ori_img_name}', image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac0f788-7c8b-41d2-a8dc-8951870814f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# F. underexposure\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "image_path = 'testdataset/ori_image'\n",
    "images = sorted(glob.glob(image_path + '/*'))[160:192]\n",
    "damage_label = 'F'\n",
    "\n",
    "\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i])\n",
    "    gamma = random.uniform(0.15, 0.3)\n",
    "    image = adjust_gamma(image, gamma)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ori_img_name = os.path.basename(images[i])\n",
    "    cv2.imwrite(f'testdataset/damaged_image/{damage_label}_{ori_img_name}', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0309f008-6f57-4827-804c-58e1099dd3db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# G condensed water\n",
    "import torch\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "image_list=[]\n",
    "image_path = 'testdataset/ori_image'\n",
    "images = sorted(glob.glob(image_path + '/*'))[192:224]\n",
    "damage_label = 'G'\n",
    "\n",
    "print(len(images))\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_list.append(image)\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.imgcorruptlike.Spatter(severity=2),] )\n",
    "\n",
    "images_aug_list = seq.augment_images(image_list)\n",
    "print(len(images_aug_list))\n",
    "\n",
    "for index in range(len(images_aug_list)):\n",
    "    ori_img_name = os.path.basename(images[index])\n",
    "    cv2.imwrite( f'testdataset/damaged_image/{damage_label}_{ori_img_name}', images_aug_list[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00d7ce9-b411-4c18-95b6-149816fa960b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# H powder cluster\n",
    "\n",
    "image_path = 'testdataset/ori_image'\n",
    "image_list=[]\n",
    "images = sorted(glob.glob(image_path + '/*'))[224:256]\n",
    "damage_label = 'H'\n",
    "\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_list.append(image)\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.imgcorruptlike.Spatter(severity=5),] )\n",
    "\n",
    "images_aug_list = seq.augment_images(image_list)\n",
    "\n",
    "for index in range(len(images_aug_list)):\n",
    "    ori_img_name = os.path.basename(images[index])\n",
    "    cv2.imwrite( f'testdataset/damaged_image/{damage_label}_{ori_img_name}', images_aug_list[index])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9d4ab714-521e-42dd-940b-6229711329d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I regionalPixelShift\n",
    "import random\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "CAM_FRONT_path = '../../Dataset/lidar_img_16200/original_image_gray'\n",
    "images = sorted(glob.glob(CAM_FRONT_path + '/*'))[14400:16200]\n",
    "\n",
    "def pixel_shift(img):\n",
    "    out = img.copy()\n",
    "    out_mid = img.copy()\n",
    "    out_mid2 = img.copy()\n",
    "    shift1 = random.randint(5, 10)\n",
    "    width1 = random.randint(12, 20)\n",
    "    x1 = random.randint(0, 1600 - 3 * width1)\n",
    "\n",
    "    out[:, x1 - 3 * width1:x1, :] = out_mid[:, x1:x1 + 3 * width1, :]\n",
    "    out[:, x1:x1 + 3 * width1, :] = out_mid2[:, x1 - 3 * width1:x1, :]\n",
    "    # out[x1 - shift1:x1 - shift1 + width1, :, :] = out[x1:x1 + width1, :, :]\n",
    "    return out\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    image = cv2.imread(images[i])\n",
    "    image = pixel_shift(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ori_img_name = os.path.basename(images[i])\n",
    "    cv2.imwrite(f'../../Dataset/lidar_img_16200/damaged_image_gray/I_regionalPixelShift/{ori_img_name}', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "48752ebe-3a5f-4e20-8678-ad01f14ca21a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# test the geerated gray image\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "img=Image.open('../../Dataset/lidar_img_16200/damaged_image_gray/F_underexposure/8e9c6424a0e642dc97d75baf6d4c6d6f.png')\n",
    "\n",
    "print(type(img))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "\n",
    "img_tensor = transform(img)\n",
    "print(type(img_tensor))\n",
    "print(img_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239a9f83-15b6-4bc1-ae37-483dd173543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create only the masked dataset \n",
    "import torch\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# sample_token as name\n",
    "image_list = []\n",
    "ori_img_name_list = []\n",
    "\n",
    "CAM_FRONT_path = '../../Dataset/lidar_img_16200/original_image_gray'\n",
    "images = sorted(glob.glob(CAM_FRONT_path + '/*'))\n",
    "\n",
    "for i in range(len(images)):\n",
    "\n",
    "        image = cv2.imread(images[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image_list.append(image)\n",
    "        ori_img_name = os.path.basename(images[i])\n",
    "        ori_img_name_list.append(ori_img_name)\n",
    "\n",
    "\n",
    "# print(len(image_list))\n",
    "    \n",
    "seq = iaa.Sequential([\n",
    "    iaa.Cutout(nb_iterations=(16, 24), size=0.2, squared=False, seed =1 )\n",
    "    , ])\n",
    "\n",
    "images_aug_list = seq.augment_images(image_list)\n",
    "\n",
    "for index in range(len(images_aug_list)):\n",
    "    # s = '%05d' % (index+1) # name format 00001\n",
    "    s = ori_img_name_list[index]\n",
    "    cv2.imwrite(f'../../Dataset/lidar_img_16200/maksed_image_gray/{s}', images_aug_list[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f86ba204-06e5-4d2e-beb3-bc419d166649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images_aug_list = []\n",
    "ori_img_name_list = []\n",
    "\n",
    "\n",
    "CAM_FRONT_path = '../../Dataset/lidar_img_16200/original_image_gray'\n",
    "# images = sorted(glob.glob(CAM_FRONT_path + '/*'))[1800:3600]\n",
    "images = sorted(glob.glob(CAM_FRONT_path + '/*'))[14624:14656]\n",
    "print(len(images))\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ori_img_name = os.path.basename(images[i])\n",
    "    cv2.imwrite(f'../../Dataset/lidar_img_16200/damaged_image_gray_all/for_porcessing/{ori_img_name}', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1216c90-490c-40cd-8d75-6bf44ba58cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.10.2",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
