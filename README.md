This study aimed to investigate the fusion approaches based on deep neural networks for image reconstruction, particularly in their ability to restore missing objects in the images. To achieve this aim, various fusion approaches were designed and tested. These approaches encompassed a combination of the feature representations with scalar weights, elementwise weights through neural network, the use of convolution layers for dimension adjustor after concatenating the feature representations and elementwise weights through mathematical functions. Notably, Fusion 1 and the new fusion through mathematical functions did not require a retraining, while Fusion 2 and 3 necessitated a retraining in the fusion part of the network.
The results indicate that sensor fusion via deep neural network can greatly improve the quality of the reconstructed images and help restore the missing objects. However, the models' performance is notably limited when confronted with new types of damages. To tackle this problem, the new fusion involving mathematical functions was proposed and achieved good performance.
